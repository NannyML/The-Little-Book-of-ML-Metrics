\chapter{Clustering}


% ---------- Mutual Info Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Mutual Info Score}
\subsection{Mutual Info Score}

The Mutual Information (MI) Score can be used to quantify the amount of information shared between two clustering assignments.
It's also particularly useful for comparing the similarity between ground-truth labels and predicted clustering labels.

% Formula
\begin{center}
    FORMULA GOES HERE
\end{center}

The MI score ranges from 0 to +infinity, where 0 indicates no mutual information and higher values signify greater
similarity. To address certain limitations of the standard MI score, such as lack of normalization and agreement by chance, variations like the
Normalized Mutual Information (NMI) score and the Adjusted Mutual Information (AMI) score were developed.

NMI ranges from 0 to 1, while AMI ranges from -1 to 1. The key difference between AMI and NMI is that AMI adjusts for chance. 
AMI equals 0 when the clustering assignments are no more similar than would be expected by chance.

\textbf{When to use Mutual Info Scores?}

Use MI you need a basic measure of shared information between two clusterings. NMI when comparing clustering results with different numbers of
clusters, as it normalizes the score to a standard range. AMI when you want to account for chance.

\coloredboxes{
    \item Symmetric. Switching true label with predicted ones will return the same score.
    \item Lower and upper bounded in the case of the NMI and AMI variations.
    \item Can be used as a consensus score.
}
{
    \item Requires knowledge of ground truth classes.
    \item A permutation of the cluster label values doesn't change the score value in any way. eg. IM([0, 0, 1], [0, 0, 1]) = IM([0, 0, 1], [1, 0, 0])

}

% ---------- rand score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Rand Score}
\subsection{Rand Score}

% ---------- adjusted rand score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Adjusted Rand Score}
\subsection{Adjusted Rand Score}

% ---------- calinski harabasz score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{CH Score}
\subsection{Calinski Harabasz Score}


% ---------- contingency matrix ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Contingency Matrix}
\subsection{Contingency Matrix}

% ---------- pair confusion matrix ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Pair Confusion Matrix}
\subsection{Pair Confusion Matrix}

% ---------- Completeness Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Completeness Score}
\subsection{Completeness Score}

% ---------- Davis Bouldin Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Davis Bouldin Score}
\subsection{Davis Bouldin Score}

% ---------- Fowlkes Mallows Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Fowlkes Mallows Score}
\subsection{Fowlkes Mallows Score}

% ---------- Homogeneity Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Homogeneity Score}
\subsection{Homogeneity Score}

% ---------- V Measure ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{V Measure}
\subsection{V Measure}

% ---------- Homogeneity Completeness V Measure ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Homogeneity Completeness V Measure}
\subsection{Homogeneity Completeness V Measure}

% ---------- Silhouette Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Silhouette Score}
\subsection{Silhouette Score}

The Silhouette Coefficient measures how well a data point fits within its assigned cluster compared to other clusters. 
It quantifies how similar a sample is to its own cluster (cohesion) compared to the nearest neighboring cluster (separation).
The Silhouette Coefficient $s(i)$ for a given data point $i$ in the cluster $C_I$, where $|C_I|$ is the number of data points in $C_I$, is given by:

\begin{center}
\tikz{
\node[inner sep=2pt, font=\Large] (a) {
{
$\displaystyle
s(i) = 
\begin{cases}
\frac{{\color{cyan}b(i)} - {\color{nmlpurple}a(i)}}{max\left\{ {\color{nmlpurple}a(i)}, {\color{cyan}b(i)} \right\}}  & if\, |C_I| > 1 \\
0  & if\, |C_I| = 1
\end{cases}
$
}
};
\draw[-latex,cyan, semithick] ($(a.north)+(-0.9,0.05)$) to[bend right=15] node[pos=1, left] {measures cohesion} +(-1,.5); 
\draw[-latex,nmlpurple, semithick] ($(a.north)+(0.2,0.05)$) to[bend left=15] node[pos=1, right] {measures separation} +(1,.5); 
% \draw[-latex,nmlpurple, semithick] ($(b.north)+(0.1,0.05)$) to[bend left=15] node[pos=1, left] {True negatives} +(-1,-.5); 
}
\end{center}

Where  $a(i)$ is the mean distance between a sample and all other points in the same cluster (mean intra-cluster distance), 
and  $b(i)$ is the mean distance between a sample and all points in the nearest different cluster (mean nearest-cluster distance). 
The value of  $s(i)$ lies between -$1$ and  $1$, where  $s(i) \approx 1$ indicates that the data point is well-clustered, 
 $s(i) \approx 0$ means the data point is on or very close to the boundary between two clusters, and  $s(i) \approx -1$ 
suggests that the data point has been misclassified into the wrong cluster.

\textbf{When to use Silhouette Score?}

Use Silhouette Score when the ground truth labels are unknown and the evaluation must be performed using the model itself.

\coloredboxes{
\item It provides a clear and intuitive measure of how well clusters are separated, +1 highly dense and -1 for incorrect clustering.
}
{
\item Silhouette Score can generally be higher for convex clusters than other clusters, such as density based clusters.
\item Higher Silhouette Score doesn't necessarily indicate that the clusters will have equal sizes; the clusters can still vary in cardinality. 
}

% ----------  Consensus Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{ Consensus Score}
\subsection{ Consensus Score}